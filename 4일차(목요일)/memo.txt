CImage는 CIFAR-100과 해상도는 같지만 배경, 조명, 객체 표현 방식에서 현저한 차이가 있습니다.
따라서 단순히 CIFAR-100 accuracy를 높이는 방식보다는 일반화 능력을 높이는 방향의 튜닝이 필수입니다. -gpt

<지금까지 튜닝 방향과 CImage 대응 전략 요약>
| 항목           | 현재 구현 상태                     | CImage 대응 제안                                                          |
| --------       | ----------------------------      | ---------------------------------------------------------------------    |
| 모델 구조       | ResNet + EfficientNet concat      | ✔ 유지 가능. **다중 특성 추출에 유리함**                                   |
| 입력 변환       | 고정된 CIFAR normalization         | CImage의 domain shift를 줄이기 위해 **CLAHE나 색상 jitter 보강** 고려      |
| 학습 기법       | CutMix, Cutout 일부 사용           | ✅ CutMix는 유효함. **Mixup 또는 Random Erasing 추가 고려**               |
| 라벨 스무딩     | 없음                               | **Label Smoothing 0.1\~0.2 적용 권장**                                   |
| 앙상블         | 미적용                             | **다양한 seed 또는 모델 조합**으로 soft voting 추천                        |
| 테스트 전략    | 단일 모델 추론                      | **Test-Time Augmentation (TTA)** 적용 가능                               |
| 모델 선택 기준 | CIFAR-100 test acc 기준          | 여전히 유지하되, **CIFAR에서 일반화 지표도 함께 고려** (예: validation loss + acc 동시에 판단) |





CLAHE는 LAB 컬러 공간의 L(밝기) 채널에만 적용되므로, 실제 효과는 어두운 배경에서 대비 향상 효과로 작용합니다.
→ ColorJitter와 함께 쓰면 밝기·색상 대비에 더 강건한 모델을 만들 수 있습니다.

test6.py 실행결과 -> Epoch 200: Train Acc: 82.66%, Val Loss: 35.8123, Val Acc: 69.74%, Test Acc: 56.31%
